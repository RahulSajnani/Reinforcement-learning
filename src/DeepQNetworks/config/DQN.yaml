trainer:
  gpus: -1
  distributed_backend: "dp"
  accumulate_grad_batches: 1
  profiler: False
  max_epochs: 50

scheduler:
  type: MultiStepLR
  args: 
    milestones: [15, 30] #[6, 8, 18]
    gamma: 0.1

optimizer:
  type: Adam
  args:
    lr: 1e-4

environment:
  position:
    start:
      x: 0.0
      y: 0.0
      z: 0.0
    end:
      x: 100.0
      y:   0.0
      z:  10.0
  quaternion:
    start:
      w_val: 1.0
      x_val: 0.0
      y_val: 0.0
      z_val: 0.0
    end:
      w_val: 1.0
      x_val: 0.0
      y_val: 0.0
      z_val: 0.0
  reward:
    goal: 1000
    collision: -100
    factor: 0.1
  sensor:
    signal_strength_factor: 0.01
  agent:
    velocity_factor: 2
    epsilon: 0.7

dataset:
  loader:
    batch_size: 4
    shuffle: False 
    sampler: None   

model:
  replay_buffer_size: 50
  in_channels: 3
  actions: 6
