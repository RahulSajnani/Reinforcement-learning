trainer:
  gpus: -1
  distributed_backend: "dp"
  accumulate_grad_batches: 1
  profiler: False
  max_epochs: 2000

scheduler:
  type: MultiStepLR
  args: 
    milestones: [15, 30] #[6, 8, 18]
    gamma: 0.1

optimizer:
  type: Adam
  args:
    lr: 1e-3

environment:
  position:
    start:
      x:   0.0
      y:   0.0
      z: -10.0
    end:
      x: 500.0
      y:   0.0
      z: -10.0
  quaternion:
    start:
      w_val: 1.0
      x_val: 0.0
      y_val: 0.0
      z_val: 0.0
    end:
      w_val: 1.0
      x_val: 0.0
      y_val: 0.0
      z_val: 0.0
  reward:
    goal: 1000
    collision: -100
    factor: 0.1
  sensor:
    signal_strength_factor: 0.01
  agent:
    velocity_factor: 2
    

dataset:
  loader:
    batch_size: 16
    shuffle: False 
    #sampler: None   

model:
  replay_buffer_size: 200
  in_channels: 3
  actions: 7
  max_epsilon: 0.9
  min_epsilon: 0.1
  stop_decay: 1000
  sync_rate: 10
  gamma: 0.9
  sample_size: 100
  
